{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 数据处理\n",
    "将共情数据集原有格式，转换成Alpaca格式，如：\n",
    "```json\n",
    "{\n",
    "    \"instruction\": \"Hello, what would you like to talk about?\",\n",
    "    \"input\": \"\",\n",
    "    \"output\": \"I am having a lot of anxiety about quitting my current job. It is too stressful but pays well\"\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f13da6367436a79d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16006218-7879-46f9-bb9b-6392d8fcd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "import json\n",
    "\n",
    "# 读取包含原始语料的 JSON 文件\n",
    "with open(\"./fine-tune_source.json\", \"r\") as file:\n",
    "    raw_data_list = json.load(file)\n",
    "\n",
    "processed_data_list = []\n",
    "\n",
    "# 处理每个原始语料\n",
    "for raw_data in raw_data_list:\n",
    "    dialogs = raw_data[\"dialog\"]\n",
    "    length = len(dialogs)\n",
    "    count = 0\n",
    "    while count < length:\n",
    "        if \"annotation\" in dialogs[count] and \"strategy\" in dialogs[count][\"annotation\"] and dialogs[count][\"annotation\"][\"strategy\"] == \"Question\" and count != length-1:\n",
    "            output_entry = {\n",
    "                \"instruction\": dialogs[count][\"content\"].strip().replace('\\n', ''),\n",
    "                \"input\": \"\",\n",
    "                \"output\": dialogs[count + 1][\"content\"].strip().replace('\\n', '')\n",
    "            }\n",
    "            processed_data_list.append(output_entry)\n",
    "            count += 2\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "# 输出整理后的数据到 JSON 文件\n",
    "with open(\"./fine-tune_alpaca_dst.json\", \"w\") as outfile:\n",
    "    json.dump(processed_data_list, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型微调\n",
    "基于intel_extension_for_transformers所提供的微调方式，使用共情数据集，采用Lora技术，对Llama-2-7b-hf进行微调，重新训练其中400多万，约6%的可调参数权重，得到模型empathy_finetune_llama_2_hf。此处微调的目的，是提高模型在对话过程中，对玩家输入所体现情感的共情能力。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e812fed48f51f91b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ad88f-16d5-4cd4-9991-528661e6655a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型微调\n",
    "from transformers import TrainingArguments\n",
    "from intel_extension_for_transformers.neural_chat.config import (\n",
    "    ModelArguments,\n",
    "    DataArguments,\n",
    "    FinetuningArguments,\n",
    "    TextGenerationFinetuningConfig,\n",
    ")\n",
    "from intel_extension_for_transformers.neural_chat.chatbot import finetune_model\n",
    "model_args = ModelArguments(model_name_or_path=\"./model/Llama-2-7b-hf\", trust_remote_code=True)\n",
    "data_args = DataArguments(train_file=\"./fine-tune_alpaca_dst.json\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model/empathy_finetune_llama_2_hf',\n",
    "    do_train=True,\n",
    "    do_eval=False,\n",
    "    num_train_epochs=3,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    save_strategy=\"no\",\n",
    "    log_level=\"info\",\n",
    "    save_total_limit=2,\n",
    "    bf16=True,\n",
    "    use_cpu=False\n",
    ")\n",
    "finetune_args = FinetuningArguments(device='cuda')\n",
    "finetune_cfg = TextGenerationFinetuningConfig(\n",
    "            model_args=model_args,\n",
    "            data_args=data_args,\n",
    "            training_args=training_args,\n",
    "            finetune_args=finetune_args,\n",
    "        )\n",
    "finetune_model(finetune_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型推理\n",
    "1. 检索增强\n",
    "简短的prompt难以全面描述游戏所展示的世界观和角色性格，基于RAG技术，利用intel_extension_for_transformers所提供的retrieval插件，使用bce-embedding-base_v1将游戏的故事文本进行向量化，加入到玩家提问的推理过程中，使chatbot的回复更符合游戏设定。\n",
    "2. prompt\n",
    "项目的对话设计为玩家扮演故事主角夏生，与另一位主角亚托莉进行对话。因此，在对话开始之前，通过prompt，提示chatbot模仿亚托莉性格，结合故事背景，以角色扮演的形式提供回答。intel_extension_for_transformers提供了cache插件，保持最初对于chatbot的prompt设定进行持续对话。\n",
    "3. 量化加速\n",
    "在推理过程中，通过intel_extension_for_transformers所提供的optimization_config，设置了4bits量化，提高玩家对话过程中的响应速度。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2efa46a1d5ec7df5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e1cff-2c60-43d4-ab85-a758208ed2d2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-05-02T09:47:12.888586Z",
     "iopub.status.busy": "2024-05-02T09:47:12.887983Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 结合RAG，玩家扮演夏生，与亚托莉进行多轮剧情对话\n",
    "from intel_extension_for_transformers.neural_chat import PipelineConfig\n",
    "from intel_extension_for_transformers.neural_chat import build_chatbot\n",
    "from intel_extension_for_transformers.neural_chat import plugins\n",
    "from intel_extension_for_transformers.transformers import RtnConfig\n",
    "from intel_extension_for_transformers.neural_chat.config import LoadingModelConfig\n",
    "from intel_extension_for_transformers.neural_chat.config import GenerationConfig\n",
    "plugins.retrieval.enable=True\n",
    "plugins.retrieval.args[\"input_path\"]=\"./atri_my_dear_moments.txt\"\n",
    "plugins.retrieval.args[\"embedding_model\"]=\"./model/bce-embedding-base_v1\"\n",
    "# plugins.cache.enable=True\n",
    "config = PipelineConfig(model_name_or_path='./model/empathy_finetune_llama_2_hf',\n",
    "                        optimization_config=RtnConfig(bits=4, compute_dtype=\"int8\", weight_dtype=\"int4_fullrange\"), \n",
    "                        loading_config=LoadingModelConfig(use_neural_speed=False),\n",
    "                        plugins=plugins)\n",
    "chatbot = build_chatbot(config)\n",
    "predict_config = GenerationConfig(use_cache=True)\n",
    "chat.predict(query='你是亚托莉，请根据你所知晓的信息，使用第一人称，与扮演夏生的我进行对话。在对话全程中，请保持你的角色特点，并使回答尽可能符合故事设定。如果你理解了这段话，那么我们就开始对话。首先请回复夏生你好。', config=predict_config)\n",
    "print(response)\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"> \").strip()\n",
    "    if prompt == \"quit\":\n",
    "        break\n",
    "    response = chatbot.predict(query=prompt, config=predict_config)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itrex",
   "language": "python",
   "name": "itrex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
